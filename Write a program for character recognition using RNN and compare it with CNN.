import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
# Load EMNIST Dataset (letters)
(ds_train, ds_test), ds_info = tfds.load(
'emnist/letters',
split=['train', 'test'],
shuffle_files=True,
as_supervised=True,
with_info=True
)
def normalize_img(image, label):
image = tf.cast(image, tf.float32) / 255.0
return image, label
BATCH_SIZE = 128
ds_train = ds_train.map(normalize_img).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
ds_test = ds_test.map(normalize_img).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
rnn_model = tf.keras.models.Sequential([
tf.keras.layers.Reshape((28, 28), input_shape=(28, 28, 1)),
tf.keras.layers.SimpleRNN(128, activation='relu'),
tf.keras.layers.Dense(128, activation='relu'),
tf.keras.layers.Dense(27, activation='softmax') # 26 letters + 1 blank
])
rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
rnn_model.summary()
cnn_model = tf.keras.models.Sequential([
tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
tf.keras.layers.MaxPooling2D((2, 2)),
tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
tf.keras.layers.MaxPooling2D((2, 2)),
tf.keras.layers.Flatten(),
tf.keras.layers.Dense(128, activation='relu'),
tf.keras.layers.Dense(27, activation='softmax')
])
cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
cnn_model.summary()
rnn_history = rnn_model.fit(ds_train, epochs=10, validation_data=ds_test)
cnn_history = cnn_model.fit(ds_train, epochs=10, validation_data=ds_test)
plt.plot(rnn_history.history['val_accuracy'], label='RNN Validation Accuracy')
plt.plot(cnn_history.history['val_accuracy'], label='CNN Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Validation Accuracy')
plt.legend()
plt.title('Character Recognition: RNN vs CNN')
plt.show()
