import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
# Step 1: Create a toy dataset (square footage vs. housing prices)
np.random.seed(42)
X_train = np.random.rand(100, 1) * 1000 # Square footage (0 to 1000 sqft)
y_train = 2000 + 0.5 * X_train + np.random.randn(100, 1) * 50 # Price = 2000 + 0.5 * sqft + noise
# Step 2: Build the linear regression model using tf.keras with ReLU activation for the output layer
model = tf.keras.Sequential([
tf.keras.layers.Dense(1, input_dim=1, activation='linear'), # Linear layer for the first layer
tf.keras.layers.ReLU() # Apply ReLU activation to output layer to ensure positive prices
])
# Step 3: Compile the model (using Mean Squared Error loss and Adam optimizer)
model.compile(optimizer='adam', loss='mse')
# Step 4: Train the model
history = model.fit(X_train, y_train, epochs=100, verbose=0)
# Step 5: Visualize the loss function
plt.plot(history.history['loss'])
plt.title('Loss Function over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss (Mean Squared Error)')
plt.show()
# Step 6: Visualize the learned linear relationship
plt.scatter(X_train, y_train, label="Data")
plt.plot(X_train, model.predict(X_train), color='red', label="Fitted line")
plt.xlabel('Square Footage')
plt.ylabel('Price')
plt.title('Learned Linear Relationship')
plt.legend()
plt.show()
# Step 7: Make predictions on new data points
new_square_footage = np.array([[1500], [2000], [2500]]) # New data points (sqft)
predictions = model.predict(new_square_footage)
# Display predictions
for sqft, price in zip(new_square_footage, predictions):
print(f"Predicted price for {sqft[0]} sqft: ${price[0]:.2f}")
